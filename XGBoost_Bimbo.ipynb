{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bimbo Python XGBoost 5 week Lag Python script adapted from R\n",
    "# Rodolfo Lomascolo e-mail: r.lomascolo@rodolfolomascolo.com\n",
    "# Adapted from code by Bohdan Pavlyshenko  http://tinyurl.com/jd6k2kr\n",
    "# All credits for Bohdan Pavlyshenko and all bugs to me.\n",
    "#\n",
    "# Due to heavy usage of memory, this script will not run in kaggle.\n",
    "# the script runs only with a minimum of 35GB of physical or physical+swap memory\n",
    "# it can take a couple of hours to train depending on your machine, disk and memory\n",
    "# I used an 8 core, 56GB of RAM Azure DS13 machine with additional 100 GB of swap\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from subprocess import check_output\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "from sklearn import cross_validation\n",
    "import scipy.stats as stats\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leemos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('READING DATA...')\n",
    "\n",
    "train = pd.read_csv('train.csv') \n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marcamos los \"targets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train and Test Read')\n",
    "\n",
    "train['target'] = train['Demanda_uni_equil']\n",
    "train.drop(['Demanda_uni_equil'],axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tst'] = 0\n",
    "test['tst'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unimos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train,test], axis=0, copy=True)\n",
    "\n",
    "print('Train and Test Concat')\n",
    "del train\n",
    "del test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculamos agregaciones por semanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,6):\n",
    "    lag = 'Lag' + str(i)\n",
    "    print('Lag:',lag)\n",
    "    \n",
    "    data1 = data[['Semana','Cliente_ID','Producto_ID','target']]\n",
    "    data1.loc[:,'Semana'] = data1['Semana'] +i\n",
    "    data1 = pd.groupby(data1,['Semana','Cliente_ID','Producto_ID']).mean() \n",
    "    data1 = data1.reset_index()\n",
    "    data1.rename(columns={'target': lag}, inplace=True)\n",
    "    data = pd.merge(data,data1,\n",
    "                    how='left',\n",
    "                    left_on=['Semana','Cliente_ID','Producto_ID'], \n",
    "                    right_on=['Semana','Cliente_ID','Producto_ID'],\n",
    "                    left_index=False, right_index=False, sort=True,\n",
    "                    suffixes=('_x', '_y'), copy=False, )\n",
    "    del data1\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TotalLags'] = data['Lag1'] + data['Lag2']+ data['Lag3']+ data['Lag4']+ data['Lag5']\n",
    "    \n",
    "data=data[data['Semana']>8]  # NOW I WORK WITH WEEKS 9,10,11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculamos features de `agencia`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nAgencia = pd.DataFrame(pd.groupby(data,['Agencia_ID','Semana'])['target'].count())\n",
    "nAgencia = nAgencia.reset_index()\n",
    "nAgencia.rename(columns={'target': 'nAgencia'}, inplace=True)\n",
    "nAgencia = pd.DataFrame(pd.groupby(nAgencia,['Agencia_ID'])['nAgencia'].mean())\n",
    "nAgencia = nAgencia.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(data, nAgencia, \n",
    "                            how='left',\n",
    "                            left_on=['Agencia_ID'], \n",
    "                            right_on=['Agencia_ID'],\n",
    "                            left_index=False, right_index=False, sort=True,\n",
    "                            suffixes=('_x', '_y'), copy=False) \n",
    "\n",
    "del nAgencia\n",
    "gc.collect()\n",
    "print('merge completo nAgencia')\n",
    "print(data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculamos features de `ruta_SAK`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nRuta_SAK = pd.DataFrame(pd.groupby(data,['Ruta_SAK','Semana'])['target'].count())\n",
    "nRuta_SAK = nRuta_SAK.reset_index()\n",
    "nRuta_SAK.rename(columns={'target': 'nRuta_SAK'}, inplace=True)\n",
    "nRuta_SAK = pd.DataFrame(pd.groupby(nRuta_SAK,['Ruta_SAK'])['nRuta_SAK'].mean())\n",
    "nRuta_SAK = nRuta_SAK.reset_index()\n",
    " \n",
    "\n",
    "data = pd.merge(data, nRuta_SAK, \n",
    "                            how='left',\n",
    "                            left_on=['Ruta_SAK'], \n",
    "                            right_on=['Ruta_SAK'],\n",
    "                            left_index=False, right_index=False, sort=True,\n",
    "                            suffixes=('_x', '_y'), copy=False) \n",
    "\n",
    "del nRuta_SAK\n",
    "gc.collect()\n",
    "print('merge completo nRuta_SAK')\n",
    "print(data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculamos features de `clientes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nCliente_ID = pd.DataFrame(pd.groupby(data,['Cliente_ID','Semana'])['target'].count())\n",
    "nCliente_ID = nCliente_ID.reset_index()\n",
    "nCliente_ID.rename(columns={'target': 'nCliente_ID'}, inplace=True)\n",
    "nCliente_ID = pd.DataFrame(pd.groupby(nCliente_ID,['Cliente_ID'])['nCliente_ID'].mean())\n",
    "nCliente_ID = nCliente_ID.reset_index()\n",
    " \n",
    "\n",
    "data = pd.merge(data, nCliente_ID, \n",
    "                            how='left',\n",
    "                            left_on=['Cliente_ID'], \n",
    "                            right_on=['Cliente_ID'],\n",
    "                            left_index=False, right_index=False, sort=True,\n",
    "                            suffixes=('_x', '_y'), copy=False) \n",
    "\n",
    "del nCliente_ID\n",
    "gc.collect()\n",
    "print('merge completo nCliente_ID')\n",
    "print(data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculamos features de `productos`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nProducto_ID = pd.DataFrame(pd.groupby(data,['Producto_ID','Semana'])['target'].count())\n",
    "nProducto_ID = nProducto_ID.reset_index()\n",
    "nProducto_ID.rename(columns={'target': 'nProducto_ID'}, inplace=True)\n",
    "nProducto_ID = pd.DataFrame(pd.groupby(nProducto_ID,['Producto_ID'])['nProducto_ID'].mean())\n",
    "nProducto_ID = nProducto_ID.reset_index()\n",
    " \n",
    "\n",
    "data = pd.merge(data, nProducto_ID, \n",
    "                            how='left',\n",
    "                            left_on=['Producto_ID'], \n",
    "                            right_on=['Producto_ID'],\n",
    "                            left_index=False, right_index=False, sort=True,\n",
    "                            suffixes=('_x', '_y'), copy=False) \n",
    "\n",
    "del nProducto_ID\n",
    "gc.collect()\n",
    "print('merge completo nProducto_ID')\n",
    "print(data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separamos en train/test y predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace(np.nan,0, inplace=True)\n",
    "\n",
    "train = data[data['tst']==0]\n",
    "predict = data[data['tst']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformamos la distribución de target a una distribución gaussiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['target'] = np.log(train['target'] + 1)\n",
    "#train2 = train.sample(n=1000000)   <-- another possible reduction of data for fast testing\n",
    "train2 = train\n",
    "y = train['target']\n",
    "X = train[[  'Agencia_ID','Canal_ID','Cliente_ID','Producto_ID','Ruta_SAK',\n",
    "             'Lag1','Lag2','Lag3','Lag4','Lag5','TotalLags',\n",
    "             'nAgencia','nRuta_SAK','nCliente_ID','nProducto_ID']]\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separamos entre train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01, random_state=1729)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definimos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlf = xgb.XGBRegressor(max_depth=10, \n",
    "                        learning_rate=0.1, \n",
    "                        n_estimators=100, \n",
    "                        silent=True, \n",
    "                        objective='reg:linear', \n",
    "                        nthread=-1, \n",
    "                        gamma=0,\n",
    "                        min_child_weight=1, \n",
    "                        max_delta_step=0, \n",
    "                        subsample=0.85, \n",
    "                        colsample_bytree=0.7, \n",
    "                        colsample_bylevel=1, \n",
    "                        reg_alpha=0, \n",
    "                        reg_lambda=1, \n",
    "                        scale_pos_weight=1, \n",
    "                        seed=1440, \n",
    "                        missing=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlf.fit(X_train, y_train, eval_metric='rmse', verbose = True, eval_set = [(X_test, y_test)],early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculamos las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the auc score\n",
    "preds = xlf.predict(X_test)\n",
    "print('\\nRoot Mean Square error of Log(Demanda) X_test\" ', mean_squared_error(y_test,preds)**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardamos el modelo en un fichero pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('bimbo_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(xlf, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
